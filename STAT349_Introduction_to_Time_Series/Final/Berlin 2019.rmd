---
title: "Stat 349 Spring 2020 Final Take-home Exam"
author: "Yuanyou Yao"
date: "2020/4/29"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
source('Gla1ve.r')
```
\section{Steps 1-3}
\subsection{AAL}
The original log return series and the ﬁtted residuals are plotted.
\flushleft
```{r}
x.original=read.csv('AAL.csv',row.names = 1)
x= timeSeries(x.original$X[-1],charvec = row.names(x.original)[-1])
par(mfrow=c(1,2))
plot(x,type='h',ylab='Index Return')
plot(residuals(GARCH.Model(x)),type='h',ylab='standardized residuals')
```
\subsubsection{The best ﬁtted model is GARCH(1,2) with the following estimated parameter values and standard errors.}
```{r}
GARCH.Fitting(x)
```
\subsubsection{The sum of the squared error of the ﬁnal model. }
```{r}
min(GARCH.Finding(x)[,1])
```
\subsubsection{Sum of Squared Error}
```{r}
GARCH.Finding(x)
```
As we can see, the criterion SSE gives us the best model above.
\subsubsection{Some Diagnostic Results}
The followings are Shapiro Test, Jarque Bera Test, Skewness Test, Kurtosis and gBox respectively.
```{r}
shapiro.test(na.omit(residuals(GARCH.Model(x))))
jarque.bera.test(na.omit(residuals(GARCH.Model(x))))
skewness(na.omit(residuals(GARCH.Model(x))))
kurtosis(na.omit(residuals(GARCH.Model(x))))
gBox(GARCH.Model(x),x=x,method='squared')
gBox(GARCH.Model(x),x=x,lags=20,plot=F,method='squared')$pvalue
```
\subsubsection{QQ plot and ACF}
```{r}
par(mfrow=c(1,2))
qqnorm(residuals(GARCH.Model(x))) 
qqline(residuals(GARCH.Model(x)))
acf(residuals(GARCH.Model(x))^2,na.action=na.omit)
```
\subsection{BBY}
The original log return series and the ﬁtted residuals are plotted.
\flushleft
```{r}
x.original=read.csv('BBY.csv',row.names = 1)
x= timeSeries(x.original$X[-1],charvec = row.names(x.original)[-1])
par(mfrow=c(1,2))
plot(x,type='h',ylab='Index Return')
plot(residuals(GARCH.Model(x)),type='h',ylab='standardized residuals')
```
\subsubsection{The best ﬁtted model is GARCH(2,2) with the following estimated parameter values and standard errors.}
```{r}
GARCH.Fitting(x)
```
\subsubsection{The sum of the squared error of the ﬁnal model. }
```{r}
min(GARCH.Finding(x)[,1])
```
\subsubsection{Sum of Squared Error}
```{r}
GARCH.Finding(x)
```
As we can see, the criterion SSE gives us the best model above.
\subsubsection{Some Diagnostic Results}
The followings are Shapiro Test, Jarque Bera Test, Skewness Test, Kurtosis and gBox respectively.
```{r}
shapiro.test(na.omit(residuals(GARCH.Model(x))))
jarque.bera.test(na.omit(residuals(GARCH.Model(x))))
skewness(na.omit(residuals(GARCH.Model(x))))
kurtosis(na.omit(residuals(GARCH.Model(x))))
gBox(GARCH.Model(x),x=x,method='squared')
gBox(GARCH.Model(x),x=x,lags=20,plot=F,method='squared')$pvalue
```
\subsubsection{QQ plot and ACF}
```{r}
par(mfrow=c(1,2))
qqnorm(residuals(GARCH.Model(x))) 
qqline(residuals(GARCH.Model(x)))
acf(residuals(GARCH.Model(x))^2,na.action=na.omit)
```
\subsection{BIIB}
The original log return series and the ﬁtted residuals are plotted.
\flushleft
```{r}
x.original=read.csv('BIIB.csv',row.names = 1)
x= timeSeries(x.original$X[-1],charvec = row.names(x.original)[-1])
par(mfrow=c(1,2))
plot(x,type='h',ylab='Index Return')
plot(residuals(GARCH.Model(x)),type='h',ylab='standardized residuals')
```
\subsubsection{The best ﬁtted model is GARCH(1,1) with the following estimated parameter values and standard errors.}
```{r}
GARCH.Fitting(x)
```
\subsubsection{The sum of the squared error of the ﬁnal model. }
```{r}
min(GARCH.Finding(x)[,1])
```
\subsubsection{Sum of Squared Error}
```{r}
GARCH.Finding(x)
```
As we can see, the criterion SSE gives us the best model above.
\subsubsection{Some Diagnostic Results}
The followings are Shapiro Test, Jarque Bera Test, Skewness Test, Kurtosis and gBox respectively.
```{r}
shapiro.test(na.omit(residuals(GARCH.Model(x))))
jarque.bera.test(na.omit(residuals(GARCH.Model(x))))
skewness(na.omit(residuals(GARCH.Model(x))))
kurtosis(na.omit(residuals(GARCH.Model(x))))
gBox(GARCH.Model(x),x=x,method='squared')
gBox(GARCH.Model(x),x=x,lags=20,plot=F,method='squared')$pvalue
```
\subsubsection{QQ plot and ACF}
```{r}
par(mfrow=c(1,2))
qqnorm(residuals(GARCH.Model(x))) 
qqline(residuals(GARCH.Model(x)))
acf(residuals(GARCH.Model(x))^2,na.action=na.omit)
```
\subsection{BSX}
The original log return series and the ﬁtted residuals are plotted.
\flushleft
```{r}
x.original=read.csv('BSX.csv',row.names = 1)
x= timeSeries(x.original$X[-1],charvec = row.names(x.original)[-1])
par(mfrow=c(1,2))
plot(x,type='h',ylab='Index Return')
plot(residuals(GARCH.Model(x)),type='h',ylab='standardized residuals')
```
\subsubsection{The best ﬁtted model is GARCH(1,2) with the following estimated parameter values and standard errors.}
```{r}
GARCH.Fitting(x)
```
\subsubsection{The sum of the squared error of the ﬁnal model. }
```{r}
min(GARCH.Finding(x)[,1])
```
\subsubsection{Sum of Squared Error}
```{r}
GARCH.Finding(x)
```
As we can see, the criterion SSE gives us the best model above.
\subsubsection{Some Diagnostic Results}
The followings are Shapiro Test, Jarque Bera Test, Skewness Test, Kurtosis and gBox respectively.
```{r}
shapiro.test(na.omit(residuals(GARCH.Model(x))))
jarque.bera.test(na.omit(residuals(GARCH.Model(x))))
skewness(na.omit(residuals(GARCH.Model(x))))
kurtosis(na.omit(residuals(GARCH.Model(x))))
gBox(GARCH.Model(x),x=x,method='squared')
gBox(GARCH.Model(x),x=x,lags=20,plot=F,method='squared')$pvalue
```
\subsubsection{QQ plot and ACF}
```{r}
par(mfrow=c(1,2))
qqnorm(residuals(GARCH.Model(x))) 
qqline(residuals(GARCH.Model(x)))
acf(residuals(GARCH.Model(x))^2,na.action=na.omit)
```
\subsection{BXP}
The original log return series and the ﬁtted residuals are plotted.
\flushleft
```{r}
x.original=read.csv('BXP.csv',row.names = 1)
x= timeSeries(x.original$X[-1],charvec = row.names(x.original)[-1])
par(mfrow=c(1,2))
plot(x,type='h',ylab='Index Return')
plot(residuals(GARCH.Model(x)),type='h',ylab='standardized residuals')
```
\subsubsection{The best ﬁtted model is GARCH(2,1) with the following estimated parameter values and standard errors.}
```{r}
GARCH.Fitting(x)
```
\subsubsection{The sum of the squared error of the ﬁnal model. }
```{r}
min(GARCH.Finding(x)[,1])
```
\subsubsection{Sum of Squared Error}
```{r}
GARCH.Finding(x)
```
As we can see, the criterion SSE gives us the best model above.
\subsubsection{Some Diagnostic Results}
The followings are Shapiro Test, Jarque Bera Test, Skewness Test, Kurtosis and gBox respectively.
```{r}
shapiro.test(na.omit(residuals(GARCH.Model(x))))
jarque.bera.test(na.omit(residuals(GARCH.Model(x))))
skewness(na.omit(residuals(GARCH.Model(x))))
kurtosis(na.omit(residuals(GARCH.Model(x))))
gBox(GARCH.Model(x),x=x,method='squared')
gBox(GARCH.Model(x),x=x,lags=20,plot=F,method='squared')$pvalue
```
\subsubsection{QQ plot and ACF}
```{r}
par(mfrow=c(1,2))
qqnorm(residuals(GARCH.Model(x))) 
qqline(residuals(GARCH.Model(x)))
acf(residuals(GARCH.Model(x))^2,na.action=na.omit)
```
\subsection{COG}
The original log return series and the ﬁtted residuals are plotted.
\flushleft
```{r}
x.original=read.csv('COG.csv',row.names = 1)
x= timeSeries(x.original$X[-1],charvec = row.names(x.original)[-1])
par(mfrow=c(1,2))
plot(x,type='h',ylab='Index Return')
plot(residuals(GARCH.Model(x)),type='h',ylab='standardized residuals')
```
\subsubsection{The best ﬁtted model is GARCH(1,2) with the following estimated parameter values and standard errors.}
```{r}
GARCH.Fitting(x)
```
\subsubsection{The sum of the squared error of the ﬁnal model. }
```{r}
min(GARCH.Finding(x)[,1])
```
\subsubsection{Sum of Squared Error}
```{r}
GARCH.Finding(x)
```
As we can see, the criterion SSE gives us the best model above.
\subsubsection{Some Diagnostic Results}
The followings are Shapiro Test, Jarque Bera Test, Skewness Test, Kurtosis and gBox respectively.
```{r}
shapiro.test(na.omit(residuals(GARCH.Model(x))))
jarque.bera.test(na.omit(residuals(GARCH.Model(x))))
skewness(na.omit(residuals(GARCH.Model(x))))
kurtosis(na.omit(residuals(GARCH.Model(x))))
gBox(GARCH.Model(x),x=x,method='squared')
gBox(GARCH.Model(x),x=x,lags=20,plot=F,method='squared')$pvalue
```
\subsubsection{QQ plot and ACF}
```{r}
par(mfrow=c(1,2))
qqnorm(residuals(GARCH.Model(x))) 
qqline(residuals(GARCH.Model(x)))
acf(residuals(GARCH.Model(x))^2,na.action=na.omit)
```
\subsection{GS}
The original log return series and the ﬁtted residuals are plotted.
\flushleft
```{r}
x.original=read.csv('GS.csv',row.names = 1)
x= timeSeries(x.original$X[-1],charvec = row.names(x.original)[-1])
par(mfrow=c(1,2))
plot(x,type='h',ylab='Index Return')
plot(residuals(GARCH.Model(x)),type='h',ylab='standardized residuals')
```
\subsubsection{The best ﬁtted model is GARCH(2,2) with the following estimated parameter values and standard errors.}
```{r}
GARCH.Fitting(x)
```
\subsubsection{The sum of the squared error of the ﬁnal model. }
```{r}
min(GARCH.Finding(x)[,1])
```
\subsubsection{Sum of Squared Error}
```{r}
GARCH.Finding(x)
```
As we can see, the criterion SSE gives us the best model above.
\subsubsection{Some Diagnostic Results}
The followings are Shapiro Test, Jarque Bera Test, Skewness Test, Kurtosis and gBox respectively.
```{r}
shapiro.test(na.omit(residuals(GARCH.Model(x))))
jarque.bera.test(na.omit(residuals(GARCH.Model(x))))
skewness(na.omit(residuals(GARCH.Model(x))))
kurtosis(na.omit(residuals(GARCH.Model(x))))
gBox(GARCH.Model(x),x=x,method='squared')
gBox(GARCH.Model(x),x=x,lags=20,plot=F,method='squared')$pvalue
```
\subsubsection{QQ plot and ACF}
```{r}
par(mfrow=c(1,2))
qqnorm(residuals(GARCH.Model(x))) 
qqline(residuals(GARCH.Model(x)))
acf(residuals(GARCH.Model(x))^2,na.action=na.omit)
```
\subsection{INTC}
The original log return series and the ﬁtted residuals are plotted.
\flushleft
```{r}
x.original=read.csv('INTC.csv',row.names = 1)
x= timeSeries(x.original$X[-1],charvec = row.names(x.original)[-1])
par(mfrow=c(1,2))
plot(x,type='h',ylab='Index Return')
plot(residuals(GARCH.Model(x)),type='h',ylab='standardized residuals')
```
\subsubsection{The best ﬁtted model is GARCH(2,2) with the following estimated parameter values and standard errors.}
```{r}
GARCH.Fitting(x)
```
\subsubsection{The sum of the squared error of the ﬁnal model. }
```{r}
min(GARCH.Finding(x)[,1])
```
\subsubsection{Sum of Squared Error}
```{r}
GARCH.Finding(x)
```
As we can see, the criterion SSE gives us the best model above.
\subsubsection{Some Diagnostic Results}
The followings are Shapiro Test, Jarque Bera Test, Skewness Test, Kurtosis and gBox respectively.
```{r}
shapiro.test(na.omit(residuals(GARCH.Model(x))))
jarque.bera.test(na.omit(residuals(GARCH.Model(x))))
skewness(na.omit(residuals(GARCH.Model(x))))
kurtosis(na.omit(residuals(GARCH.Model(x))))
gBox(GARCH.Model(x),x=x,method='squared')
gBox(GARCH.Model(x),x=x,lags=20,plot=F,method='squared')$pvalue
```
\subsubsection{QQ plot and ACF}
```{r}
par(mfrow=c(1,2))
qqnorm(residuals(GARCH.Model(x))) 
qqline(residuals(GARCH.Model(x)))
acf(residuals(GARCH.Model(x))^2,na.action=na.omit)
```
\subsection{NEE}
The original log return series and the ﬁtted residuals are plotted.
\flushleft
```{r}
x.original=read.csv('NEE.csv',row.names = 1)
x= timeSeries(x.original$X[-1],charvec = row.names(x.original)[-1])
par(mfrow=c(1,2))
plot(x,type='h',ylab='Index Return')
plot(residuals(GARCH.Model(x)),type='h',ylab='standardized residuals')
```
\subsubsection{The best ﬁtted model is GARCH(2,1) with the following estimated parameter values and standard errors.}
```{r}
GARCH.Fitting(x)
```
\subsubsection{The sum of the squared error of the ﬁnal model. }
```{r}
min(GARCH.Finding(x)[,1])
```
\subsubsection{Sum of Squared Error}
```{r}
GARCH.Finding(x)
```
As we can see, the criterion SSE gives us the best model above.
\subsubsection{Some Diagnostic Results}
The followings are Shapiro Test, Jarque Bera Test, Skewness Test, Kurtosis and gBox respectively.
```{r}
shapiro.test(na.omit(residuals(GARCH.Model(x))))
jarque.bera.test(na.omit(residuals(GARCH.Model(x))))
skewness(na.omit(residuals(GARCH.Model(x))))
kurtosis(na.omit(residuals(GARCH.Model(x))))
gBox(GARCH.Model(x),x=x,method='squared')
gBox(GARCH.Model(x),x=x,lags=20,plot=F,method='squared')$pvalue
```
\subsubsection{QQ plot and ACF}
```{r}
par(mfrow=c(1,2))
qqnorm(residuals(GARCH.Model(x))) 
qqline(residuals(GARCH.Model(x)))
acf(residuals(GARCH.Model(x))^2,na.action=na.omit)
```
\subsection{TXN}
The original log return series and the ﬁtted residuals are plotted.
\flushleft
```{r}
x.original=read.csv('TXN.csv',row.names = 1)
x= timeSeries(x.original$X[-1],charvec = row.names(x.original)[-1])
par(mfrow=c(1,2))
plot(x,type='h',ylab='Index Return')
plot(residuals(GARCH.Model(x)),type='h',ylab='standardized residuals')
```
\subsubsection{The best ﬁtted model is GARCH(2,2) with the following estimated parameter values and standard errors.}
```{r}
GARCH.Fitting(x)
```
\subsubsection{The sum of the squared error of the ﬁnal model. }
```{r}
min(GARCH.Finding(x)[,1])
```
\subsubsection{Sum of Squared Error}
```{r}
GARCH.Finding(x)
```
As we can see, the criterion SSE gives us the best model above.
\subsubsection{Some Diagnostic Results}
The followings are Shapiro Test, Jarque Bera Test, Skewness Test, Kurtosis and gBox respectively.
```{r}
shapiro.test(na.omit(residuals(GARCH.Model(x))))
jarque.bera.test(na.omit(residuals(GARCH.Model(x))))
skewness(na.omit(residuals(GARCH.Model(x))))
kurtosis(na.omit(residuals(GARCH.Model(x))))
gBox(GARCH.Model(x),x=x,method='squared')
gBox(GARCH.Model(x),x=x,lags=20,plot=F,method='squared')$pvalue
```
\subsubsection{QQ plot and ACF}
```{r}
par(mfrow=c(1,2))
qqnorm(residuals(GARCH.Model(x))) 
qqline(residuals(GARCH.Model(x)))
acf(residuals(GARCH.Model(x))^2,na.action=na.omit)
```
\section{Step 5}
\subsection{}
Sample mean and standard deviation are:
```{r}
y=read.csv('Data.csv',row.names = 1)
y.return=cbind(y$AAL,y$BBY,y$BIIB,y$BSX,y$BXP,y$COG,y$GS,y$INTC,y$NEE,y$TXN)
sam=(y$BBY+y$BIIB+y$BSX+y$TXN+y$AAL+y$NEE+y$INTC+y$BXP+y$COG+y$GS)/10
sam.mean = mean(sam)
sam.sd=sd(sam)
c=rep(1/10,10)
object=function(x){
  1/mean(x[1]*y.return[,1]+x[2]*y.return[,2]++x[3]*y.return[,3]+x[4]*y.return[,4]+x[5]*y.return[,5]+x[6]*y.return[,6]+x[7]*y.return[,7]+x[8]*y.return[,8]+x[9]*y.return[,9]++x[10]*y.return[,10])
}
par.l=rep(0,10)
par.u=rep(1,10)
A = matrix(rep(1,10),1,byrow=TRUE)
lin.l=1
lin.u=1
nlcon= function(x){
  sd(x[1]*y.return[,1]+x[2]*y.return[,2]++x[3]*y.return[,3]+x[4]*y.return[,4]+x[5]*y.return[,5]+x[6]*y.return[,6]+x[7]*y.return[,7]+x[8]*y.return[,8]+x[9]*y.return[,9]++x[10]*y.return[,10])
}
nlcon1=function(x){
  mean(x[1]*y.return[,1]+x[2]*y.return[,2]++x[3]*y.return[,3]+x[4]*y.return[,4]+x[5]*y.return[,5]+x[6]*y.return[,6]+x[7]*y.return[,7]+x[8]*y.return[,8]+x[9]*y.return[,9]++x[10]*y.return[,10])
}
nlin.l = c(0,0)
nlin.u = c(sam.sd,+Inf)

x1=residuals(GARCH.Model(y$AAL))
x2=residuals(GARCH.Model(y$BBY))
x3=residuals(GARCH.Model(y$BIIB))
x4=residuals(GARCH.Model(y$BSX))
x5=residuals(GARCH.Model(y$BXP))
x6=residuals(GARCH.Model(y$COG))
x7=residuals(GARCH.Model(y$GS))
x8=residuals(GARCH.Model(y$INTC))
x9=residuals(GARCH.Model(y$NEE))
x10=residuals(GARCH.Model(y$TXN))
sam.1=(x1+x2+x3+x4+x5+x6+x7+x8+x9+x10)[-2:-1]/10
sam.1.mean=mean(sam.1)
sam.1.sd=sd(sam.1)
object.1=function(x){
  1/mean(x[1]*x1[-2:-1]+x[2]*x2[-2:-1]+x[3]*x3[-2:-1]+x[4]*x4[-2:-1]+x[5]*x5[-2:-1]+x[6]*x6[-2:-1]+x[7]*x7[-2:-1]+x[8]*x8[-2:-1]+x[9]*x9[-2:-1]+x[10]*x10[-2:-1])
  }
nlcon.1= function(x){
sd(x[1]*x1[-2:-1]+x[2]*x2[-2:-1]+x[3]*x3[-2:-1]+x[4]*x4[-2:-1]+x[5]*x5[-2:-1]+x[6]*x6[-2:-1]+x[7]*x7[-2:-1]+x[8]*x8[-2:-1]+x[9]*x9[-2:-1]+x[10]*x10[-2:-1])
}
nlcon1.1=function(x){
  mean(x[1]*x1[-2:-1]+x[2]*x2[-2:-1]+x[3]*x3[-2:-1]+x[4]*x4[-2:-1]+x[5]*x5[-2:-1]+x[6]*x6[-2:-1]+x[7]*x7[-2:-1]+x[8]*x8[-2:-1]+x[9]*x9[-2:-1]+x[10]*x10[-2:-1])
}

y.price=cbind(y$Close.8,y$Close,y$Close.1,y$Close.2,y$Close.3,y$Close.4,y$Close.5,y$Close.6,y$Close.7,y$Close.9)
sam.2=log(rowSums(y.price[-1,])/10)-log(rowSums(y.price[-nrow(y.price),]/10))
sam.2.mean=mean(sam.2)
sam.2.sd=sd(sam.2)
object.2=function(x){
  1/mean((log(x[1]*y.price[-1,1]+x[2]*y.price[-1,2]+x[3]*y.price[-1,3]+x[4]*y.price[-1,4]+x[5]*y.price[-1,5]+x[6]*y.price[-1,6]+x[7]*y.price[-1,7]+x[8]*y.price[-1,8]+x[9]*y.price[-1,9]+x[10]*y.price[-1,10])-
            log(x[1]*y.price[-nrow(y.price),1]+x[2]*y.price[-nrow(y.price),2]+x[3]*y.price[-nrow(y.price),3]+x[4]*y.price[-nrow(y.price),4]+x[5]*y.price[-nrow(y.price),5]+x[6]*y.price[-nrow(y.price),6]+x[7]*y.price[-nrow(y.price),7]+x[8]*y.price[-nrow(y.price),8]+x[9]*y.price[-nrow(y.price),9]+x[10]*y.price[-nrow(y.price),10])))
}
nlcon.2= function(x){
  sd(log(x[1]*y.price[-1,1]+x[2]*y.price[-1,2]+x[3]*y.price[-1,3]+x[4]*y.price[-1,4]+x[5]*y.price[-1,5]+x[6]*y.price[-1,6]+x[7]*y.price[-1,7]+x[8]*y.price[-1,8]+x[9]*y.price[-1,9]+x[10]*y.price[-1,10])-log(x[1]*y.price[-nrow(y.price),1]+x[2]*y.price[-nrow(y.price),2]+x[3]*y.price[-nrow(y.price),3]+x[4]*y.price[-nrow(y.price),4]+x[5]*y.price[-nrow(y.price),5]+x[6]*y.price[-nrow(y.price),6]+x[7]*y.price[-nrow(y.price),7]+x[8]*y.price[-nrow(y.price),8]+x[9]*y.price[-nrow(y.price),9]+x[10]*y.price[-nrow(y.price),10]))
}
nlcon1.2=function(x){
  mean((log(x[1]*y.price[-1,1]+x[2]*y.price[-1,2]+x[3]*y.price[-1,3]+x[4]*y.price[-1,4]+x[5]*y.price[-1,5]+x[6]*y.price[-1,6]+x[7]*y.price[-1,7]+x[8]*y.price[-1,8]+x[9]*y.price[-1,9]+x[10]*y.price[-1,10])-
            log(x[1]*y.price[-nrow(y.price),1]+x[2]*y.price[-nrow(y.price),2]+x[3]*y.price[-nrow(y.price),3]+x[4]*y.price[-nrow(y.price),4]+x[5]*y.price[-nrow(y.price),5]+x[6]*y.price[-nrow(y.price),6]+x[7]*y.price[-nrow(y.price),7]+x[8]*y.price[-nrow(y.price),8]+x[9]*y.price[-nrow(y.price),9]+x[10]*y.price[-nrow(y.price),10])))
}
mean(sam)
sd(sam)
```
\subsection{}
the best (c1,c2,...,c10), the sample mean and standard deviation are:
```{r}
donlp2(c, object, par.u=par.u, par.l=par.l,
       A,lin.l=lin.l,lin.u=lin.u,
       nlin=list(nlcon,nlcon1),
       nlin.u=nlin.u, nlin.l=nlin.l)$par
nlcon1(donlp2(c, object, par.u=par.u, par.l=par.l,
       A,lin.l=lin.l,lin.u=lin.u,
       nlin=list(nlcon,nlcon1),
       nlin.u=nlin.u, nlin.l=nlin.l)$par)
nlcon(donlp2(c, object, par.u=par.u, par.l=par.l,
       A,lin.l=lin.l,lin.u=lin.u,
       nlin=list(nlcon,nlcon1),
       nlin.u=nlin.u, nlin.l=nlin.l)$par)
```
\section{Step 6}
\subsection{}
Sample mean and standard deviation are:
```{r}
mean(sam.1)
sd(sam.1)
```
\subsection{}
the best (c1,c2,...,c10), the sample mean and standard deviation are:
```{r}
donlp2(c, object.1, par.u=par.u, par.l=par.l,
       A,lin.l=lin.l,lin.u=lin.u,
       nlin=list(nlcon.1,nlcon1.1),
       nlin.u=c(sam.1.sd,+Inf), nlin.l=c(0,sam.1.mean))$par
nlcon1.1(donlp2(c, object.1, par.u=par.u, par.l=par.l,
       A,lin.l=lin.l,lin.u=lin.u,
       nlin=list(nlcon.1,nlcon1.1),
       nlin.u=c(sam.1.sd,+Inf), nlin.l=c(0,sam.1.mean))$par)
nlcon.1(donlp2(c, object.1, par.u=par.u, par.l=par.l,
       A,lin.l=lin.l,lin.u=lin.u,
       nlin=list(nlcon.1,nlcon1.1),
       nlin.u=c(sam.1.sd,+Inf), nlin.l=c(0,sam.1.mean))$par)
```

\section{Step 7}
\subsection{}
Sample mean and standard deviation are:
```{r}
mean(sam.2)
sd(sam.2)
```
\subsection{}
the best (c1,c2,...,c10), the sample mean and standard deviation are:
```{r}
donlp2(c, object.2, par.u=par.u, par.l=par.l,
       A,lin.l=lin.l,lin.u=lin.u,
       nlin=list(nlcon.2,nlcon1.2),
       nlin.u=c(sam.2.sd,+Inf), nlin.l=c(0,sam.2.mean))$par
nlcon1.2(donlp2(c, object.2, par.u=par.u, par.l=par.l,
       A,lin.l=lin.l,lin.u=lin.u,
       nlin=list(nlcon.2,nlcon1.2),
       nlin.u=c(sam.2.sd,+Inf), nlin.l=c(0,sam.2.mean))$par)
nlcon.2(donlp2(c, object.2, par.u=par.u, par.l=par.l,
       A,lin.l=lin.l,lin.u=lin.u,
       nlin=list(nlcon.2,nlcon1.2),
       nlin.u=c(sam.2.sd,+Inf), nlin.l=c(0,sam.2.mean))$par)
```
\section{Step 8}
The original data and the ﬁtted residuals are plotted.
\flushleft
```{r}
par(mfrow=c(1,2))
plot(sam.2,type='h',ylab='Index Return')
plot(residuals(GARCH.Model(sam.2)),type='h',ylab='standardized residuals')
```
The best ﬁtted model is GARCH(2,2) with the following estimated parameter values and standard errors.
```{r}
GARCH.Fitting(sam.2)
```
The sum of the squared error of the ﬁnal model.
```{r}
min(GARCH.Finding(sam.2)[,1])
```
Sum of Squared Error.
```{r}
GARCH.Finding(sam.2)
```
As we can see, the criterion SSE gives us the best model above.\\
\newline
Sample mean and standard deviation are:
```{r}
mean(residuals(GARCH.Model(sam.2)),na.rm = T)
sd(residuals(GARCH.Model(sam.2)),na.rm = T)
```
Some Diagnostic Results\\
\newline
The followings are Shapiro Test, Jarque Bera Test, Skewness Test, Kurtosis and gBox respectively.
```{r}
shapiro.test(na.omit(residuals(GARCH.Model(sam.2))))
jarque.bera.test(na.omit(residuals(GARCH.Model(sam.2))))
skewness(na.omit(residuals(GARCH.Model(sam.2))))
kurtosis(na.omit(residuals(GARCH.Model(sam.2))))
gBox(GARCH.Model(sam.2),x=sam.2,method='squared')
gBox(GARCH.Model(sam.2),x=sam.2,lags=20,plot=F,method='squared')$pvalue
```
\subsubsection{QQ plot and ACF}
```{r}
par(mfrow=c(1,2))
qqnorm(residuals(GARCH.Model(sam.2))) 
qqline(residuals(GARCH.Model(sam.2)))
acf(residuals(GARCH.Model(sam.2))^2,na.action=na.omit)
```
\section{Step 9}
The original data and the ﬁtted residuals are plotted.
\flushleft
```{r}
Step9.fun=function(x){
 log(x[1]*y.price[-1,1]+x[2]*y.price[-1,2]+x[3]*y.price[-1,3]+x[4]*y.price[-1,4]+x[5]*y.price[-1,5]+x[6]*y.price[-1,6]+x[7]*y.price[-1,7]+x[8]*y.price[-1,8]+x[9]*y.price[-1,9]+x[10]*y.price[-1,10])-
            log(x[1]*y.price[-nrow(y.price),1]+x[2]*y.price[-nrow(y.price),2]+x[3]*y.price[-nrow(y.price),3]+x[4]*y.price[-nrow(y.price),4]+x[5]*y.price[-nrow(y.price),5]+x[6]*y.price[-nrow(y.price),6]+x[7]*y.price[-nrow(y.price),7]+x[8]*y.price[-nrow(y.price),8]+x[9]*y.price[-nrow(y.price),9]+x[10]*y.price[-nrow(y.price),10])
}
Step9 = Step9.fun(donlp2(c, object.2, par.u=par.u, par.l=par.l,
       A,lin.l=lin.l,lin.u=lin.u,
       nlin=list(nlcon.2,nlcon1.2),
       nlin.u=c(sam.2.sd,+Inf), nlin.l=c(0,sam.2.mean))$par)
par(mfrow=c(1,2))
plot(Step9,type='h',ylab='Index Return')
plot(residuals(GARCH.Model(Step9)),type='h',ylab='standardized residuals')
```
The best ﬁtted model is GARCH(1,2) with the following estimated parameter values and standard errors.
```{r}
GARCH.Fitting(Step9)
```
The sum of the squared error of the ﬁnal model.
```{r}
min(GARCH.Finding(Step9)[,1])
```
Sum of Squared Error.
```{r}
GARCH.Finding(Step9)
```
As we can see, the criterion SSE gives us the best model above.\\
\newline
Sample mean and standard deviation are:
```{r}
mean(residuals(GARCH.Model(Step9)),na.rm = T)
sd(residuals(GARCH.Model(Step9)),na.rm = T)
```
Some Diagnostic Results\\
\newline
The followings are Shapiro Test, Jarque Bera Test, Skewness Test, Kurtosis and gBox respectively.
```{r}
shapiro.test(na.omit(residuals(GARCH.Model(Step9))))
jarque.bera.test(na.omit(residuals(GARCH.Model(Step9))))
skewness(na.omit(residuals(GARCH.Model(Step9))))
kurtosis(na.omit(residuals(GARCH.Model(Step9))))
gBox(GARCH.Model(Step9),x=Step9,method='squared')
gBox(GARCH.Model(Step9),x=Step9,lags=20,plot=F,method='squared')$pvalue
```
\subsubsection{QQ plot and ACF}
```{r}
par(mfrow=c(1,2))
qqnorm(residuals(GARCH.Model(Step9))) 
qqline(residuals(GARCH.Model(Step9)))
acf(residuals(GARCH.Model(Step9))^2,na.action=na.omit)
```
\section{Step 10}
We have noticed that, using donlp2 algorithm has one obvious problem from step 5 to step 10. The uppper bound of standard deviation violates our initial sample. After reading the document for this algorithm, we figure that we can set some parameter in the donlp() that alleviates the problem. Since the two standard deviations are close enough, we can accept the optimization results.\\
\newline
Another way to avoid this is to set the upper bound a little bit smaller. That can ensure the portfolio's standard deviation is truly smaller then the original one.